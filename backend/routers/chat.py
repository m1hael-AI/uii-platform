from typing import List, Optional
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy import select, delete, or_, update, func
from sqlalchemy.exc import IntegrityError
from datetime import datetime
import asyncio
import json
import logging
import yaml
from pathlib import Path

from services.openai_service import generate_chat_response, stream_chat_response
from services.context_manager import is_context_overflow, compress_context_task
from dependencies import get_db, get_current_user, rate_limiter
from models import User, ChatSession, Message, MessageRole, Agent, PendingAction, WebinarLibrary, WebinarSchedule, UserMemory
from config import settings
from loguru import logger
from services.chat_session_service import get_or_create_chat_session

router = APIRouter(prefix="/chat", tags=["chat"])

# Create AsyncSessionLocal for background tasks
database_url = settings.database_url.replace("postgresql://", "postgresql+asyncpg://")
bg_engine = create_async_engine(database_url, echo=False, pool_pre_ping=True)
AsyncSessionLocal = sessionmaker(bg_engine, class_=AsyncSession, expire_on_commit=False)

# --- GREETINGS MAPPING ---
# --- GREETINGS MAPPING ---
def load_greetings():
    try:
        path = Path(__file__).parent.parent / "resources" / "default_prompts.yaml"
        if not path.exists():
            print(f"WARNING: Prompts file not found at {path}")
            return {}
        with open(path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        
        # Transform to simple dict {slug: greeting}
        agents = data.get("agents", {})
        return {slug: props.get("greeting") for slug, props in agents.items() if props.get("greeting")}
    except Exception as e:
        print(f"Error loading greetings: {e}")
        return {}

GREETINGS = load_greetings()

# --- SSE NOTIFICATION MANAGER ---
class NotificationManager:
    def __init__(self):
        # user_id -> set of queues (one per connection/tab)
        self.connections: dict[int, set[asyncio.Queue]] = {}

    async def connect(self, user_id: int) -> asyncio.Queue:
        if user_id not in self.connections:
            self.connections[user_id] = set()
        queue = asyncio.Queue()
        self.connections[user_id].add(queue)
        print(f"SSE: User {user_id} connected. Active tabs: {len(self.connections[user_id])}")
        return queue

    def disconnect(self, user_id: int, queue: asyncio.Queue):
        if user_id in self.connections:
            self.connections[user_id].discard(queue)
            if not self.connections[user_id]:
                del self.connections[user_id]
        print(f"SSE: User {user_id} disconnected.")

    async def broadcast(self, user_id: int, message: dict):
        """Send message to all open tabs of a user"""
        if user_id not in self.connections:
            return
            
        # Serialize once
        data = f"data: {json.dumps(message, ensure_ascii=False)}\n\n"
        
        # Send to all queues
        for queue in self.connections[user_id]:
            await queue.put(data)
            
manager = NotificationManager()


# Request Models
class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatMessage] 
    agent_id: Optional[str] = "mentor"
    webinar_id: Optional[int] = None
    save_user_message: bool = True # Control duplication

# History Response Model
class HistoryMessage(BaseModel):
    role: str
    content: str
    created_at: str

class HistoryResponse(BaseModel):
    messages: List[HistoryMessage]
    last_read_at: Optional[str] = None
    is_new_session: bool = False  # True if session has no messages (even archived)

class ChatSessionDTO(BaseModel):
    id: int
    agent_id: str
    agent_name: str
    agent_avatar: Optional[str]
    last_message: str # FIX: Added back
    last_message_at: Optional[str]
    has_unread: bool = False

async def ensure_initial_sessions(db: AsyncSession, user_id: int):
    """
    Ensures that a new user has all necessary initial sessions (Agents + Assistant)
    Created here to be called from both /sessions and /unread-status for instant cold start.
    
    NOTE: Creates greeting messages for AGENTS immediately.
    Main Assistant greeting is created on-demand via /chat/history (with 1-second delay).
    """
    # 1. Check if user already has sessions
    q = select(ChatSession).where(ChatSession.user_id == user_id)
    res = await db.execute(q)
    if res.first():
        return False # Already has sessions
        
    # 2. Setup initial sessions
    initial_slugs = ["startup_expert", "python", "hr", "analyst", "main_assistant"]
    
    for slug in initial_slugs:
        # For agents, check existence. Assistant is a special slug.
        if slug != "main_assistant":
            agent_res = await db.execute(select(Agent).where(Agent.slug == slug))
            agent_obj = agent_res.scalar_one_or_none()
            if not agent_obj: continue
        
        try:
            # Use atomic get_or_create
            new_session = await get_or_create_chat_session(db, user_id, slug)
            session_created = True
        except Exception as e:
            logger.error(f"Error creating initial session for {slug}: {e}")
            logger.warning(f"Session for user {user_id}, agent {slug} already exists (race condition)")
            continue
        
        # Create greeting message for AGENTS (not for main_assistant)
        # Only if we just created the session in this request
        if session_created and slug != "main_assistant":
            welcome_text = agent_obj.greeting_message if agent_obj.greeting_message else GREETINGS.get(slug, "ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?")
            
            msg = Message(
                session_id=new_session.id,
                role=MessageRole.ASSISTANT,
                content=welcome_text,
                created_at=datetime.utcnow()
            )
            db.add(msg)
            
            # Update session timestamps
            new_session.last_message_at = datetime.utcnow()
            new_session.last_read_at = datetime(2000, 1, 1)  # Mark as unread
            
            await db.commit()
    
    return True

@router.get("/sessions", response_model=List[ChatSessionDTO])
async def get_user_sessions(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
    background_tasks: BackgroundTasks = BackgroundTasks() # Add BackgoundTasks
):
    """Get all active chat sessions for the user with last message preview"""
    # 1. Get all sessions for user (excluding specific webinar chats if any, or including?)
    # Usually sidebar shows Agent chats. Webinar chats might be separate or same.
    # Let's include everything that is NOT bound to a specific webinar (general agent chats)
    # OR all valid sessions. The frontend list seems to be Agents.
    
    q = select(ChatSession, Agent).join(Agent, ChatSession.agent_slug == Agent.slug).where(
        ChatSession.user_id == current_user.id,
        ChatSession.is_active == True,
        ChatSession.schedule_id == None,
        ChatSession.library_id == None # Only general agent chats
    ).order_by(ChatSession.last_message_at.desc())
    
    result = await db.execute(q)
    rows = result.all() # [(ChatSession, Agent), ...]
    
    if not rows:
        # --- COLD START LOGIC ---
        await ensure_initial_sessions(db, current_user.id)
        # Re-fetch rows (exclude assistant from the main list if desired, but previously it seemed we wanted them?)
        # Wait, the frontend list usually DOES NOT show the main assistant if it's in the sidebar.
        # But for notification "bell" we check all.
        # For this endpoint /sessions which powers the "Agents" page, we typically exclude main_assistant if it lives in sidebar only.
        # The previous code had `q.where(ChatSession.agent_slug != "main_assistant")`. Let's keep that constraint if it was there.
        # Actually in the VERY first version it didn't filtering.
        # But in Step 405 replacement it added filtering. 
        # Let's apply filtering to be safe as per previous intent.
        
        q_agents = q.where(ChatSession.agent_slug != "main_assistant")
        result = await db.execute(q_agents)
        rows = result.all()
    else:
        # If we had rows initially, we might still want to filter main_assistant if it was returned by general query?
        # The general query joins Agent. 
        # If main_assistant is in Agent table, it might appear.
        # Let's filter it out in python or query to be consistent.
        rows = [r for r in rows if r[0].agent_slug != "main_assistant"]

    sessions_dto = []
    
    for session, agent in rows:
        # Get last message content
        msg_q = select(Message).where(Message.session_id == session.id).order_by(Message.created_at.desc()).limit(1)
        msg_res = await db.execute(msg_q)
        last_msg = msg_res.scalar_one_or_none()
        
        last_content = last_msg.content if last_msg else "ÐÐ°Ñ‡Ð½Ð¸Ñ‚Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³"
        if len(last_content) > 60:
            last_content = last_content[:60] + "..."
            
        # Red dot logic
        has_unread = False
        if session.last_message_at:
            if not session.last_read_at:
                has_unread = True
            elif session.last_message_at > session.last_read_at:
                has_unread = True
        
        # DEBUG LOG for specific agent
        if agent.slug == 'startup_expert':
             print(f"ðŸ‘‰ [BACKEND] GET_SESSIONS 'startup_expert': LastMsg={session.last_message_at}, LastRead={session.last_read_at}, Unread={has_unread}")

        sessions_dto.append(ChatSessionDTO(
            id=session.id,
            agent_id=agent.slug,
            agent_name=agent.name,
            agent_avatar=agent.avatar_url,
            last_message=last_content, # FIX: Passed correctly
            last_message_at=session.last_message_at.isoformat() if session.last_message_at else None,
            has_unread=has_unread
        ))
        
    return sessions_dto

@router.get("/history", response_model=HistoryResponse)
async def get_chat_history(
    webinar_id: Optional[int] = None,
    agent_id: Optional[str] = "mentor",
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get chat history for current user and context"""
    q = select(ChatSession).where(
        ChatSession.user_id == current_user.id
    )
    
    if webinar_id is not None:
        # Check both tables as ID might refer to either (assuming ID collision risk is handled or acceptable for now)
        q = q.where(or_(ChatSession.library_id == webinar_id, ChatSession.schedule_id == webinar_id))
    else:
        # If no webinar, stick to agent slug AND ensure it's not a webinar session
        q = q.where(ChatSession.agent_slug == agent_id).where(ChatSession.schedule_id == None, ChatSession.library_id == None)
        
    result = await db.execute(q)
    sessions = result.scalars().all()
    
    # Handle race condition: if multiple sessions exist, use the first one
    if len(sessions) > 1:
        logger.warning(f"Multiple sessions found for user {current_user.id}, agent {agent_id}. Using first one.")
        session = sessions[0]
    elif len(sessions) == 1:
        session = sessions[0]
    else:
        session = None
    
        # âœ… 1. Auto-create session if it doesn't exist (Lazy Load)
        # This ensures we have a place to put the greeting immediately
        session = await get_or_create_chat_session(
            db=db,
            user_id=current_user.id,
            agent_slug=agent_id,
            webinar_id=webinar_id
        )
        
        
        # âœ… 2. Create Synchronous Greeting
        # Get greeting text
        if agent_id == "main_assistant":
            greeting_text = "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ Ð²Ð°Ñˆ AI-Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº. Ð¯ Ð²ÑÐµÐ³Ð´Ð° Ð¿Ð¾Ð´ Ñ€ÑƒÐºÐ¾Ð¹ Ð² Ð±Ð¾ÐºÐ¾Ð²Ð¾Ð¹ Ð¿Ð°Ð½ÐµÐ»Ð¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ Ð»ÑŽÐ±Ñ‹Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð¼. Ð¡ Ñ‡ÐµÐ³Ð¾ Ð½Ð°Ñ‡Ð½ÐµÐ¼?"
        else:
             # Look up agent name if needed
            agent_name = "AI Assistant"
            if agent_id == "ai_tutor":
                agent_name = "AI Ð¢ÑŒÑŽÑ‚Ð¾Ñ€"
            else:
                 agent_res = await db.execute(select(Agent).where(Agent.slug == agent_id))
                 agent_obj = agent_res.scalar_one_or_none()
                 if agent_obj: agent_name = agent_obj.name

            greeting_text = GREETINGS.get(agent_id, f"ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ {agent_name}. Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?")
            
        greeting_msg = Message(
            session_id=session.id,
            role=MessageRole.ASSISTANT,
            content=greeting_text,
            created_at=datetime.utcnow()
        )
        db.add(greeting_msg)
        await db.commit()
        await db.refresh(session)
        
        # Return newly created history directly
        return HistoryResponse(
            messages=[
                HistoryMessage(
                    role=greeting_msg.role.value,
                    content=greeting_msg.content,
                    created_at=greeting_msg.created_at.isoformat()
                )
            ],
            last_read_at=session.last_read_at.isoformat() if session.last_read_at else None,
            is_new_session=True
        )
        
    # Get messages (exclude archived and system messages)
    msgs_q = select(Message).where(
        Message.session_id == session.id,
        Message.is_archived == False,
        Message.role != MessageRole.SYSTEM
    ).order_by(Message.created_at)
    res = await db.execute(msgs_q)
    messages = res.scalars().all()
    
    # Check if this is a truly new session (no messages at all, even archived)
    all_msgs_q = select(Message).where(Message.session_id == session.id)
    all_msgs_res = await db.execute(all_msgs_q)
    all_messages = all_msgs_res.scalars().all()
    is_new_session = len(all_messages) == 0
    
    # If session exists but has NO messages (e.g. manually cleared), trigger sync greeting
    # CRITICAL: Check all_messages (total history), not just filters, to avoid duplicates on refresh
    if len(all_messages) == 0 and agent_id:
         # Same logic as above but for existing session
        if agent_id == "main_assistant":
            greeting_text = "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ Ð²Ð°Ñˆ AI-Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº. Ð¯ Ð²ÑÐµÐ³Ð´Ð° Ð¿Ð¾Ð´ Ñ€ÑƒÐºÐ¾Ð¹ Ð² Ð±Ð¾ÐºÐ¾Ð²Ð¾Ð¹ Ð¿Ð°Ð½ÐµÐ»Ð¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ Ð»ÑŽÐ±Ñ‹Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð¼. Ð¡ Ñ‡ÐµÐ³Ð¾ Ð½Ð°Ñ‡Ð½ÐµÐ¼?"
        else:
            agent_name = "AI Assistant" # Fallback
            if agent_id == "ai_tutor":
                agent_name = "AI Ð¢ÑŒÑŽÑ‚Ð¾Ñ€"
            else:
                 # Look up agent name if needed
                 agent_res = await db.execute(select(Agent).where(Agent.slug == agent_id))
                 agent_obj = agent_res.scalar_one_or_none()
                 if agent_obj: agent_name = agent_obj.name
            
            greeting_text = GREETINGS.get(agent_id, f"ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ {agent_name}. Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?")
            
        greeting_msg = Message(
            session_id=session.id,
            role=MessageRole.ASSISTANT,
            content=greeting_text,
            created_at=datetime.utcnow()
        )
        db.add(greeting_msg)
        await db.commit()
        
        # Add to messages list to return immediately
        messages.append(greeting_msg)
    
    return HistoryResponse(
        messages=[
            HistoryMessage(
                role=m.role.value, 
                content=m.content, 
                created_at=m.created_at.isoformat()
            ) for m in messages
        ],
        last_read_at=session.last_read_at.isoformat() if session.last_read_at else None,
        is_new_session=is_new_session
    )

@router.post("/completions")
async def chat_completions(
    request: ChatRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
    _: None = Depends(rate_limiter)
):
    # 1. Get Webinar Context
    webinar_context = ""
    if request.webinar_id:
        # Try retrieving context from WebinarLibrary (most likely source of transcripts)
        res = await db.execute(select(WebinarLibrary).where(WebinarLibrary.id == request.webinar_id))
        w = res.scalar_one_or_none()
        if w and w.transcript_context:
            webinar_context = w.transcript_context
        else:
            # Fallback (rare): try Schedule, though likely no transcript yet
            res_sch = await db.execute(select(WebinarSchedule).where(WebinarSchedule.id == request.webinar_id))
            w_sch = res_sch.scalar_one_or_none()
            if w_sch and hasattr(w_sch, 'transcript_context') and w_sch.transcript_context:
                 webinar_context = w_sch.transcript_context

    # 2. Get or Create Session
    chat_session = await get_or_create_chat_session(
        db=db,
        user_id=current_user.id,
        agent_slug=request.agent_id or "ai_tutor",
        webinar_id=request.webinar_id
    )
        
        # No delayed greeting here. Greeting is handled by get_chat_history or created synchronously if needed.

    # 3. Save User Message
    # 3. Save User Message
    # We take the LAST message from the client as the new one
    if request.messages and request.save_user_message:
        last_user_msg_content = request.messages[-1].content
        user_db_msg = Message(
            session_id=chat_session.id,
            role=MessageRole.USER,
            content=last_user_msg_content
        )
        db.add(user_db_msg)
        
        # â° Update last_message_at for proactivity timer
        chat_session.last_message_at = datetime.utcnow()
        
        # ðŸ”ª Kill Switch: Delete pending proactive tasks for this agent
        # If user initiates conversation, we don't need to send proactive message
        agent_slug = request.agent_id or "ai_tutor"
        
        # Check how many pending tasks exist before deletion
        pending_count = await db.scalar(
            select(func.count(PendingAction.id))
            .where(PendingAction.user_id == current_user.id)
            .where(PendingAction.agent_slug == agent_slug)
            .where(PendingAction.status == "pending")
        )
        
        if pending_count and pending_count > 0:
            logger.info(f"ðŸ”ª Kill Switch: Deleting {pending_count} pending task(s) for user={current_user.id}, agent={agent_slug}")
        
        result = await db.execute(
            delete(PendingAction)
            .where(PendingAction.user_id == current_user.id)
            .where(PendingAction.agent_slug == agent_slug)
            .where(PendingAction.status == "pending")
        )
        
        await db.commit()
        
        # Log successful deletion
        if pending_count and pending_count > 0:
            logger.info(f"âœ… Kill Switch: Successfully deleted {pending_count} pending task(s)")

    # 4. Building Context (Memory v2)
    # =========================================================================
    # A. Fetch History from DB (Active only)
    # We ignore frontend 'messages' list for context building. We trust the DB.
    # This automatically includes [SUMMARY] messages (role=SYSTEM) from compression.
    
    # Load all non-archived messages (rely on context compression for token management)
    # Context overflow check will trigger compression if needed
    history_result = await db.execute(
        select(Message)
        .where(Message.session_id == chat_session.id)
        .where(Message.is_archived == False)
        .order_by(Message.created_at.desc()) # Fetch latest first
    )
    # Reverse to restore chronological order (Oldest -> Newest)
    history_messages = list(reversed(history_result.scalars().all()))
    
    # B. Fetch Memory (for Injection)
    # 1. Global Profile (UserMemory)
    user_memory_res = await db.execute(select(UserMemory).where(UserMemory.user_id == current_user.id))
    user_memory = user_memory_res.scalar_one_or_none()
    global_profile = user_memory.narrative_summary if user_memory and user_memory.narrative_summary else "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾"
    
    # 2. Local Profile (User-Agent Profile)
    # Previously 'local_summary'. Now 'user_agent_profile'.
    local_profile = chat_session.user_agent_profile if chat_session.user_agent_profile else "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾"

    # C. Prepare System Prompt
    system_prompt = "You are a helpful AI Assistant."
    
    # C. Prepare System Prompt (Unified Logic)
    # Always load from DB first
    agent_slug = request.agent_id or "ai_tutor"
    agent_res = await db.execute(select(Agent).where(Agent.slug == agent_slug))
    agent_obj = agent_res.scalar_one_or_none()
    
    if agent_obj and agent_obj.system_prompt:
        system_prompt = agent_obj.system_prompt
    else:
        system_prompt = "You are a helpful AI Assistant." # Fallback

    # D. INJECTION
    
    # 1. Webinar Context Injection
    
    # D. INJECTION
    
    # 1. Memory Injection (FIRST)
    # We rely on specific placeholders in the prompt text: {user_profile}, {user_agent_profile}
    system_prompt = system_prompt.replace("{user_profile}", global_profile)
    system_prompt = system_prompt.replace("{user_agent_profile}", local_profile)
    system_prompt = system_prompt.replace("{local_summary}", local_profile) # Legacy support

    # 2. Webinar Context Injection (SECOND - Dynamic Size)
    if webinar_context:
        from config import settings # Lazy import
        from services.context_manager import get_model_limit
        from utils.token_counter import count_string_tokens_async, count_tokens_from_messages_async, get_encoding
        
        model_name = settings.openai_model
        max_model_tokens = get_model_limit(model_name)
        
        # Calculate Used Tokens
        # A. System Prompt (so far)
        system_prompt_tokens = await count_string_tokens_async(system_prompt, model=model_name)
        
        # B. Chat History
        # Convert history_messages (DB objects) to dicts for counting
        history_dicts = [{"role": m.role.value, "content": m.content} for m in history_messages]
        history_tokens = await count_tokens_from_messages_async(history_dicts, model=model_name)
        
        # C. Response Buffer (Reserve space for answer)
        RESPONSE_BUFFER = 4000 # Safe default for long answers
        
        # Calculate Available Space
        used_tokens = system_prompt_tokens + history_tokens + RESPONSE_BUFFER
        available_context_tokens = max(1000, max_model_tokens - used_tokens)
        
        # Measure context
        context_tokens = await count_string_tokens_async(webinar_context, model=model_name)
        
        safe_context = webinar_context
        if context_tokens > available_context_tokens:
            logger.warning(f"âš ï¸ Webinar context too large ({context_tokens} tokens). Truncating to {available_context_tokens} tokens (Model Limit: {max_model_tokens} - Used: {used_tokens}).")
            
            # Smart Truncation via tiktoken
            encoding = get_encoding(model_name)
            encoded = encoding.encode(webinar_context)
            truncated_encoded = encoded[:available_context_tokens]
            safe_context = encoding.decode(truncated_encoded)

        formatted_context = (
            f"\n=== ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ Ð’Ð•Ð‘Ð˜ÐÐÐ Ð (Ð¢Ð ÐÐÐ¡ÐšÐ Ð˜ÐŸÐ¦Ð˜Ð¯) ===\n"
            f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¢ÐžÐ›Ð¬ÐšÐž ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ:\n"
            f"--- ÐÐÐ§ÐÐ›Ðž Ð¢Ð•ÐšÐ¡Ð¢Ð ---\n"
            f"{safe_context}\n"
            f"--- ÐšÐžÐÐ•Ð¦ Ð¢Ð•ÐšÐ¡Ð¢Ð ---\n"
            f"==========================================\n"
        )
        
        # Inject into placeholder
        if "{webinar_context}" in system_prompt:
            system_prompt = system_prompt.replace("{webinar_context}", formatted_context)
        else:
            # If agent doesn't have placeholder but context exists -> that's weird but not fatal.
            pass
            
    else:
        # NO CONTEXT PROVIDED
        # Check if it was supposed to be AI Tutor?
        if agent_slug == "ai_tutor":
            logger.error(f"ðŸš¨ AI Tutor invoked without webinar_context! Agent will be blind.")
            
        # Clean up placeholder
        system_prompt = system_prompt.replace("{webinar_context}", "")

    # E. Construct Conversation
    conversation = [{"role": "system", "content": system_prompt}]
    
    for m in history_messages:
        conversation.append({"role": m.role.value, "content": m.content})
        
    # --- Context Management Check ---
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ñ‡Ð°Ñ‚Ð° Ð¸Ð· Ð‘Ð”
    from services.settings_service import get_chat_settings
    chat_settings = await get_chat_settings(db)
    
    current_model = chat_settings.user_chat_model # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼Ð¸
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ
    if await is_context_overflow(
        conversation, 
        max_tokens=chat_settings.context_soft_limit, 
        threshold=chat_settings.context_threshold, 
        model=current_model
    ):
        background_tasks.add_task(
            compress_context_task, 
            session_id=chat_session.id, 
            keep_last_n=chat_settings.context_compression_keep_last,
            model=chat_settings.compression_model  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ ÑÐ¶Ð°Ñ‚Ð¸Ñ
        )
        
    # 5. Stream & Save
    async def response_generator():
        full_response = ""
        try:
            async for chunk in stream_chat_response(
                conversation, 
                model=chat_settings.user_chat_model,
                temperature=chat_settings.user_chat_temperature,
                max_tokens=chat_settings.user_chat_max_tokens,
                user_id=current_user.id,
                agent_slug=request.agent_id or "ai_tutor"
            ):
                full_response += chunk
                yield chunk
        except Exception as e:
            print(f"Stream error: {e}")
            yield f"[Error: {str(e)}]"
        finally:
             if full_response:
                 try:
                     # Create a new local saving logic because 'db' might be closed or detached
                     # Actually asyncpg connection might be closed by FastAPI.
                     # We reuse 'db' and try. If it fails, we ignore log.
                     ai_msg = Message(
                         session_id=chat_session.id,
                         role=MessageRole.ASSISTANT,
                         content=full_response
                     )
                     db.add(ai_msg)
                     
                     # â° Update last_message_at for proactivity timer
                     # Use explicit UPDATE to avoid detached instance issues after previous commits
                     now_utc = datetime.utcnow()
                     await db.execute(
                         update(ChatSession)
                         .where(ChatSession.id == chat_session.id)
                         .values(last_message_at=now_utc)
                     )
                     
                     await db.commit()
                     print(f"ðŸ‘‰ [BACKEND] MSG_SAVED. Session={chat_session.id}, Agent={agent_slug}, MsgTime={now_utc}")
                     
                     # ðŸ”” Notify User (AI Response Finished)
                     # Trigger global update to refresh lists and bells
                     await manager.broadcast(current_user.id, {"type": "chatStatusUpdate"})
                     
                 except Exception as ex:
                     logger.error(f"âŒ Failed to save AI response to database: {ex}", exc_info=True)

    return StreamingResponse(
        response_generator(), 
        media_type="text/event-stream", 
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no" # Prevent Nginx/Proxy buffering
        }
    )

@router.post("/read")
async def mark_chat_read(
    request: Request,
    webinar_id: Optional[int] = None,
    agent_id: Optional[str] = "mentor",
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Mark chat session as read (update last_read_at)"""
    # DEBUG LOG
    source = request.headers.get("X-Caller-Source", "Unknown")
    print(f"ðŸ‘‰ [BACKEND] MARK_READ. Agent={agent_id}, User={current_user.id}, Source={source}, Time={datetime.utcnow()}")
    
    q = select(ChatSession).where(ChatSession.user_id == current_user.id)
    
    if webinar_id is not None:
        q = q.where(or_(ChatSession.library_id == webinar_id, ChatSession.schedule_id == webinar_id))
    else:
        q = q.where(ChatSession.agent_slug == agent_id, ChatSession.library_id == None, ChatSession.schedule_id == None)
        
    result = await db.execute(q)
    session = result.scalar_one_or_none()
    
    if not session:
        # Session not found - nothing to mark read yet
        return {"status": "ok", "message": "No session found"}
        
    session.last_read_at = datetime.utcnow()
    await db.commit()
    
    # ðŸ”” Notify User (Read Status Changed)
    # ðŸ”” Notify User (Read Status Changed)
    # FIX: Use specific event 'chatReadUpdate' instead of generic 'chatStatusUpdate' 
    # to avoid infinite loop (Frontend reloads history on statusUpdate -> calls read -> triggers statusUpdate)
    await manager.broadcast(current_user.id, {"type": "chatReadUpdate"})
    
    return {"status": "ok", "last_read_at": session.last_read_at.isoformat()}


@router.get("/unread-status")
async def get_unread_status(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Check if there are ANY unread messages across all user sessions.
    Used for the global header bell icon.
    """
    # 0. Trigger Cold Start if needed (Ensures notifications work on first layout load)
    await ensure_initial_sessions(db, current_user.id)

    # 1. Check Agent sessions
    # We need detailed info for the frontend to decide where to route (agent vs assistant)
    q = select(ChatSession).where(
        ChatSession.user_id == current_user.id,
        ChatSession.is_active == True,
        ChatSession.schedule_id == None,
        ChatSession.library_id == None
    )
    res = await db.execute(q)
    sessions = res.scalars().all()
    
    sessions_data = []
    has_global_unread = False
    
    for session in sessions:
        has_unread = False
        if session.last_message_at:
            if not session.last_read_at:
                has_unread = True
            elif session.last_message_at > session.last_read_at:
                has_unread = True
        
        if has_unread:
            has_global_unread = True
            
        sessions_data.append({
            "agent_slug": session.agent_slug,
            "unread_count": 1 if has_unread else 0
        })
    
    return {
        "has_unread": has_global_unread,
        "sessions": sessions_data
    }




@router.get("/notifications/stream")
async def stream_notifications(
    request: Request,
    current_user: User = Depends(get_current_user)
):
    """
    SSE Endpoint for real-time notifications.
    Client connects here and hangs waiting for events.
    """
    queue = await manager.connect(current_user.id)
    
    async def event_generator():
        try:
            while True:
                # Check for client disconnect
                if await request.is_disconnected():
                    break
                    
                # Wait for data with timeout to send keepalive
                try:
                    data = await asyncio.wait_for(queue.get(), timeout=15.0)
                    yield data
                except asyncio.TimeoutError:
                    # Keep-alive (comment character for SSE)
                    yield ": keepalive\n\n"
                    
        except Exception as e:
            print(f"SSE Stream Error: {e}")
        finally:
            manager.disconnect(current_user.id, queue)
            
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )
