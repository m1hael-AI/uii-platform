from typing import List, Dict, Any
from loguru import logger
from utils.token_counter import count_tokens_from_messages_async, count_string_tokens

# –õ–∏–º–∏—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π (Token Context Window) - Data 2026
MODEL_LIMITS = {
    # GPT-4.1 Family
    "gpt-4.1": 1000000,
    "gpt-4.1-mini": 1000000,

    # GPT-5 Family
    "gpt-5": 272000,
    "gpt-5-mini": 400000,

    # Legacy / Stable
    "gpt-4o": 128000,
    "gpt-4o-mini": 128000,
}

DEFAULT_LIMIT = 128000

def get_model_limit(model: str) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"""
    return MODEL_LIMITS.get(model, DEFAULT_LIMIT)

async def is_context_overflow(
    messages: List[Dict[str, Any]], 
    max_tokens: int = 0, # 0 = use model limit
    threshold: float = 0.9, # Default to 90% as requested
    model: str = "gpt-4o"
) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏ "–º—è–≥–∫–∏–π" –ª–∏–º–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    –ï—Å–ª–∏ max_tokens=0, –±–µ—Ä–µ—Ç –ª–∏–º–∏—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –æ –º–æ–¥–µ–ª—è—Ö.
    
    Threshold 0.9 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –µ—Å–ª–∏ –∑–∞–Ω—è—Ç–æ > 90% –æ–∫–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True.
    """
    limit = max_tokens
    if limit <= 0:
        limit = get_model_limit(model)
        
    soft_limit = limit * threshold
    
    # Use Async Token Counter to prevent blocking main loop
    total_tokens = await count_tokens_from_messages_async(messages, model)
    
    # DEBUG: Always log the check
    logger.info(f"üîç Context Check: {total_tokens} tokens | Soft Limit: {int(soft_limit)} ({threshold*100}% of {limit}) | Model: {model}")
    
    if total_tokens > soft_limit:
        logger.info(f"‚ö†Ô∏è Context Overflow: {total_tokens}/{limit} tokens (Threshold: {int(soft_limit)})")
        return True
    
    logger.info(f"‚úÖ Context OK: {total_tokens} < {int(soft_limit)}")    
    return False


# === Logic for Compression ===

from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete, update, func
from models import Message, MessageRole, ChatSession
from services.openai_service import generate_chat_response
from database import async_engine
from sqlalchemy.orm import sessionmaker

# Factory for creating independent sessions in background tasks
AsyncSessionLocal = sessionmaker(
    async_engine,
    class_=AsyncSession,
    expire_on_commit=False,
)

async def compress_context_task(
    session_id: int, 
    keep_last_n: int = 20,
    model: str = "gpt-4o"
):
    """
    –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–∂–∞—Ç–∏—è –∏—Å—Ç–æ—Ä–∏–∏ (Context Compression / Summarization).
    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (Context Overflow).
    –°–æ–∑–¥–∞–µ—Ç –°–û–ë–°–¢–í–ï–ù–ù–£–Æ —Å–µ—Å—Å–∏—é –ë–î.
    """
    async with AsyncSessionLocal() as db:
        try:
            logger.info(f"üßπ Starting context compression for session {session_id}...")
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∂–∞—Ç–∏—è –∏–∑ ChatSettings
            from services.settings_service import get_chat_settings
            chat_settings = await get_chat_settings(db)
            
            # 1. –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –ù–ï –∞—Ä—Ö–∏–≤–Ω—ã–µ)
            query = select(Message).where(
                Message.session_id == session_id,
                Message.is_archived == False  # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ
            ).order_by(Message.created_at.asc())
            result = await db.execute(query)
            all_messages = result.scalars().all()
        
            if len(all_messages) <= keep_last_n:
                 logger.info(f"Skipping compression: not enough messages ({len(all_messages)} <= {keep_last_n})")
                 return
    
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Å–∂–∞—Ç–∏—è (–≤—Å—ë, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N)
            # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Å–∞–º–º–∞—Ä–∏ (–º—ã —ç—Ç–æ –ø–æ–π–º–µ–º –ø–æ –º–∞—Ä–∫–µ—Ä—É), —Ç–æ –≤–∫–ª—é—á–∞–µ–º –∏ –µ–≥–æ
            messages_to_compress = all_messages[:-keep_last_n]
            messages_to_keep = all_messages[-keep_last_n:]
            
            if not messages_to_compress:
                return
    
            logger.info(f"Compressing {len(messages_to_compress)} messages...")
    
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞
            previous_summary = "–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–∞–º–º–∞—Ä–∏."
            text_to_compress = ""
            
            for msg in messages_to_compress:
                role = "AI" if msg.role == MessageRole.ASSISTANT else "User"
                
                # Check for existing summary in the first message(s)
                if msg.role == MessageRole.SYSTEM and "[SUMMARY]" in msg.content:
                     # Extract content after standard prefix or take whole content
                     content = msg.content
                     prefix = "[SUMMARY] –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n"
                     if prefix in content:
                         previous_summary = content.replace(prefix, "")
                     else:
                         previous_summary = content
                     continue
                
                text_to_compress += f"{role}: {msg.content}\n"
    
            if not text_to_compress.strip():
                return
    
            # 2. –ó–∞–ø—Ä–æ—Å –∫ LLM
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç –∏–∑ ProactivitySettings
            from models import ProactivitySettings
            proactivity_settings_result = await db.execute(select(ProactivitySettings))
            proactivity_settings = proactivity_settings_result.scalar_one_or_none()

            if not proactivity_settings or not proactivity_settings.compression_prompt:
                logger.error("‚ùå ProactivitySettings or compression_prompt missing in DB! Cannot compress context.")
                return

            prompt_template = proactivity_settings.compression_prompt

            # Format the prompt with both parts
            try:
                prompt = prompt_template.format(
                    previous_summary=previous_summary,
                    text_to_compress=text_to_compress
                )
            except KeyError:
                logger.error("‚ùå Prompt format mismatch in compression! The prompt in DB doesn't match the code variables.")
                return
    
            new_summary_text = await generate_chat_response(
                messages=[{"role": "user", "content": prompt}],
                model=chat_settings.compression_model,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Å–∂–∞—Ç–∏—è –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
                temperature=chat_settings.compression_temperature,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è —Å–∂–∞—Ç–∏—è
                max_tokens=chat_settings.compression_max_tokens  # –ò—Å–ø–æ–ª—å–∑—É–µ–º max_tokens –¥–ª—è —Å–∂–∞—Ç–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å None)
            )
            
            final_summary_content = f"[SUMMARY] –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n{new_summary_text}"
            
            # 3. –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î
            # –í–º–µ—Å—Ç–æ —É–¥–∞–ª–µ–Ω–∏—è –¥–µ–ª–∞–µ–º Soft Delete (–∞—Ä—Ö–∏–≤–∞—Ü–∏—é)
            ids_to_archive = [m.id for m in messages_to_compress]
            
            # –í–ê–ñ–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å is_archived = True
            await db.execute(
                update(Message)
                .where(Message.id.in_(ids_to_archive))
                .values(is_archived=True)
            )
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ-—Å–∞–º–º–∞—Ä–∏ –∏ –≤—Å—Ç–∞–≤–ª—è–µ–º –µ–≥–æ "–≤ –ø—Ä–æ—à–ª–æ–µ" 
            # (—Å—Ç–∞–≤–∏–º –≤—Ä–µ–º—è —á—É—Ç—å —Ä–∞–Ω—å—à–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è)
            first_kept_msg_time = messages_to_keep[0].created_at if messages_to_keep else datetime.utcnow()
            summary_time = first_kept_msg_time  # –ò–ª–∏ slightly before
            
            summary_msg = Message(
                session_id=session_id,
                role=MessageRole.SYSTEM, # System —Ä–æ–ª—å –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                content=final_summary_content,
                created_at=summary_time # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –ø–æ—Ä—è–¥–æ–∫ ID –º–æ–∂–µ—Ç —Å–±–∏—Ç—å—Å—è, –Ω–æ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–ø–∞—Å–µ—Ç
            )
            db.add(summary_msg)
            
            await db.commit()
            logger.info(f"‚úÖ Context compressed. Archived {len(ids_to_archive)} msgs. New summary length: {len(final_summary_content)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error during context compression: {e}")
            # –ù–µ —Ä–µ–π–∑–∏–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –Ω–µ –∫–ª–∞—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å, –µ—Å–ª–∏ —ç—Ç–æ –≤—ã–∑–æ–≤–µ—Ç—Å—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (—Ö–æ—Ç—è –º—ã –±—É–¥–µ–º –≤—ã–∑—ã–≤–∞—Ç—å –≤ —Ñ–æ–Ω–µ)
