from typing import List, Dict, Any
from loguru import logger
from utils.token_counter import count_tokens_from_messages, count_string_tokens

# –õ–∏–º–∏—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π (Token Context Window) - Data 2026

# –õ–∏–º–∏—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π (Token Context Window) - Data 2026
MODEL_LIMITS = {
    # GPT-4.1 Family
    "gpt-4.1": 1000000,
    "gpt-4.1-mini": 1000000,

    # GPT-5 Family
    "gpt-5": 272000,
    "gpt-5-mini": 400000,

    # Legacy / Stable
    "gpt-4o": 128000,
    "gpt-4o-mini": 128000,
}

DEFAULT_LIMIT = 128000

def get_model_limit(model: str) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"""
    return MODEL_LIMITS.get(model, DEFAULT_LIMIT)

def is_context_overflow(
    messages: List[Dict[str, Any]], 
    max_tokens: int = 0, # 0 = use model limit
    threshold: float = 0.9, # Default to 90% as requested
    model: str = "gpt-4o"
) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏ "–º—è–≥–∫–∏–π" –ª–∏–º–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    –ï—Å–ª–∏ max_tokens=0, –±–µ—Ä–µ—Ç –ª–∏–º–∏—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –æ –º–æ–¥–µ–ª—è—Ö.
    
    Threshold 0.9 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –µ—Å–ª–∏ –∑–∞–Ω—è—Ç–æ > 90% –æ–∫–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True.
    """
    limit = max_tokens
    if limit <= 0:
        limit = get_model_limit(model)
        
    soft_limit = limit * threshold
    total_tokens = count_tokens_from_messages(messages, model)
    
    # DEBUG: Always log the check
    logger.info(f"üîç Context Check: {total_tokens} tokens | Soft Limit: {int(soft_limit)} ({threshold*100}% of {limit}) | Model: {model}")
    
    if total_tokens > soft_limit:
        logger.info(f"‚ö†Ô∏è Context Overflow: {total_tokens}/{limit} tokens (Threshold: {int(soft_limit)})")
        return True
    
    logger.info(f"‚úÖ Context OK: {total_tokens} < {int(soft_limit)}")    
    return False


# === Logic for Compression ===

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete, func
from models import Message, MessageRole, ChatSession
from services.openai_service import generate_chat_response
from database import async_engine
from sqlalchemy.orm import sessionmaker

# Factory for creating independent sessions in background tasks
AsyncSessionLocal = sessionmaker(
    async_engine,
    class_=AsyncSession,
    expire_on_commit=False,
)

async def compress_context_task(
    session_id: int, 
    keep_last_n: int = 20,
    model: str = "gpt-4o"
):
    """
    –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è —Å–∂–∞—Ç–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞.
    –°–æ–∑–¥–∞–µ—Ç –°–û–ë–°–¢–í–ï–ù–ù–£–Æ —Å–µ—Å—Å–∏—é –ë–î.
    """
    async with AsyncSessionLocal() as db:
        try:
            logger.info(f"üßπ Starting context compression for session {session_id}...")
            
            # 1. –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
            query = select(Message).where(Message.session_id == session_id).order_by(Message.created_at.asc())
            result = await db.execute(query)
            all_messages = result.scalars().all()
        
            if len(all_messages) <= keep_last_n:
                 logger.info(f"Skipping compression: not enough messages ({len(all_messages)} <= {keep_last_n})")
                 return
    
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Å–∂–∞—Ç–∏—è (–≤—Å—ë, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N)
            # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è —Å–∞–º–º–∞—Ä–∏ (–º—ã —ç—Ç–æ –ø–æ–π–º–µ–º –ø–æ –º–∞—Ä–∫–µ—Ä—É), —Ç–æ –≤–∫–ª—é—á–∞–µ–º –∏ –µ–≥–æ
            messages_to_compress = all_messages[:-keep_last_n]
            messages_to_keep = all_messages[-keep_last_n:]
            
            if not messages_to_compress:
                return
    
            logger.info(f"Compressing {len(messages_to_compress)} messages...")
    
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∞–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞
            text_to_compress = ""
            user_name_heuristic = "User"
            
            for msg in messages_to_compress:
                role = "AI" if msg.role == MessageRole.ASSISTANT else "User"
                if msg.role == MessageRole.SYSTEM and "[SUMMARY]" in msg.content:
                     text_to_compress += f"–ü–†–ï–î–´–î–£–©–ï–ï –ö–†–ê–¢–ö–û–ï –°–û–î–ï–†–ñ–ê–ù–ò–ï:\n{msg.content}\n\n"
                     continue
                
                text_to_compress += f"{role}: {msg.content}\n"
    
            if not text_to_compress.strip():
                return
    
            # 2. –ó–∞–ø—Ä–æ—Å –∫ LLM
            prompt = (
                f"–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–∏–∞–ª–æ–≥–∞ –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.\n"
                f"–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –ü–û–î–†–û–ë–ù–û–ï —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞.\n\n"
                f"–¢–†–ï–ë–û–í–ê–ù–ò–Ø:\n"
                f"1. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –í–°–ï –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Å—É–∂–¥–∞–ª–∏—Å—å\n"
                f"2. –°–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ—Ç–≤–µ—Ç—ã AI\n"
                f"3. –£–∫–∞–∂–∏ –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã, –∏–º–µ–Ω–∞, –¥–∞—Ç—ã, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã\n"
                f"4. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –ø–æ —Ç–µ–º–∞–º (–∏—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–µ—Ä—ã –∏–ª–∏ –Ω—É–º–µ—Ä–∞—Ü–∏—é)\n"
                f"5. –ò–≥–Ω–æ—Ä–∏—Ä—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã\n"
                f"6. –°–∞–º–º–∞—Ä–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–µ—Ç–∞–ª—å–Ω—ã–º, —á—Ç–æ–±—ã AI –º–æ–≥ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n\n"
                f"=== –î–ò–ê–õ–û–ì ===\n"
                f"{text_to_compress[:100000]}\n" # Hard limit safety
                f"=== –ö–û–ù–ï–¶ –î–ò–ê–õ–û–ì–ê ===\n\n"
                f"–°–æ–∑–¥–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏:"
            )
    
            new_summary_text = await generate_chat_response(
                messages=[{"role": "user", "content": prompt}],
                model="gpt-4.1-mini", # –î–µ—à–µ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–∂–∞—Ç–∏—è
                temperature=0.2 # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                # max_tokens –ù–ï —É–∫–∞–∑—ã–≤–∞–µ–º ‚Äî —Å–∞–º–º–∞—Ä–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            )
            
            final_summary_content = f"[SUMMARY] –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n{new_summary_text}"
            
            # 3. –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î
            # –£–¥–∞–ª—è–µ–º —Å–∂–∞—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            ids_to_delete = [m.id for m in messages_to_compress]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–æ –ª–∏ —É –Ω–∞—Å —É–∂–µ —Å–æ–æ–±—â–µ–Ω–∏–µ-—Å–∞–º–º–∞—Ä–∏ –≤ –Ω–∞—á–∞–ª–µ?
            # –ï—Å–ª–∏ –¥–∞, –º—ã –µ–≥–æ —É–¥–∞–ª—è–µ–º –≤–º–µ—Å—Ç–µ —Å–æ –≤—Å–µ–º–∏ –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ. 
            # –ò–ª–∏, –µ—Å–ª–∏ –º—ã —Ö–æ—Ç–∏–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å ID, –æ–±–Ω–æ–≤–ª—è–µ–º. 
            # –ü—Ä–æ—â–µ: —É–¥–∞–ª–∏—Ç—å –≤—Å—ë —Å—Ç–∞—Ä–æ–µ, —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.
            
            # –í–ê–ñ–ù–û: –£–¥–∞–ª—è–µ–º –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
            await db.execute(delete(Message).where(Message.id.in_(ids_to_delete)))
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ-—Å–∞–º–º–∞—Ä–∏ –∏ –≤—Å—Ç–∞–≤–ª—è–µ–º –µ–≥–æ "–≤ –ø—Ä–æ—à–ª–æ–µ" 
            # (—Å—Ç–∞–≤–∏–º –≤—Ä–µ–º—è —á—É—Ç—å —Ä–∞–Ω—å—à–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è)
            first_kept_msg_time = messages_to_keep[0].created_at if messages_to_keep else datetime.utcnow()
            summary_time = first_kept_msg_time  # –ò–ª–∏ slightly before
            
            summary_msg = Message(
                session_id=session_id,
                role=MessageRole.SYSTEM, # System —Ä–æ–ª—å –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                content=final_summary_content,
                created_at=summary_time # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –ø–æ—Ä—è–¥–æ–∫ ID –º–æ–∂–µ—Ç —Å–±–∏—Ç—å—Å—è, –Ω–æ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–ø–∞—Å–µ—Ç
            )
            db.add(summary_msg)
            
            await db.commit()
            logger.info(f"‚úÖ Context compressed. Deleted {len(ids_to_delete)} msgs. New summary length: {len(final_summary_content)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error during context compression: {e}")
            # –ù–µ —Ä–µ–π–∑–∏–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –Ω–µ –∫–ª–∞—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å, –µ—Å–ª–∏ —ç—Ç–æ –≤—ã–∑–æ–≤–µ—Ç—Å—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (—Ö–æ—Ç—è –º—ã –±—É–¥–µ–º –≤—ã–∑—ã–≤–∞—Ç—å –≤ —Ñ–æ–Ω–µ)
