from loguru import logger
import asyncio
import re
from typing import List, Optional
from datetime import datetime, timedelta, timezone
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, text
from models import NewsItem, NewsStatus
from services.openai_service import generate_embedding

from services.news.perplexity import NewsItemSchema, PerplexityClient, WriterResponse
from models import NewsItem, NewsStatus, User, UserMemory
from config import settings



class NewsManager:
    """
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –Ω–æ–≤–æ—Å—Ç–µ–π:
    1. –ê–≥—Ä–µ–≥–∞—Ü–∏—è (add_news_items) —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π.
    2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (trigger_generation).
    3. –ü–æ–∏—Å–∫ –∏ –≤—ã–¥–∞—á–∞ (get_news_feed).
    """
    def __init__(self, db: AsyncSession):
        self.db = db
        self.perplexity = PerplexityClient()

    async def add_news_items(self, items: List[NewsItemSchema]) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ –±–∞–∑—É.
        –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ URL –∏ –ø–æ –≤–µ–∫—Ç–æ—Ä—É).
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.
        """
        added_count = 0
        
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö URL –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
        # (–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –Ω–µ –¥–µ–ª–∞—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å –µ—Å–ª–∏ –∏—Ö –º–Ω–æ–≥–æ)
        # –ù–æ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–º.
        
        for item in items:
            try:
                # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ URL (–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
                # –ï—Å–ª–∏ —Ç–∞–∫–æ–π source_url —É–∂–µ –µ—Å—Ç—å –≤ JSON –º–∞—Å—Å–∏–≤–µ source_urls
                # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –º–∞—Å—Å–∏–≤ —ç—Ç–æ—Ç URL –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                # PostgreSQL JSONB operator @> but here using text search for simplicity or precise logic
                stmt = select(NewsItem.id).where(
                    func.jsonb_path_exists(NewsItem.source_urls, f'$[*] ? (@ == "{item.source_url}")')
                )
                # Note: jsonb_path_exists is pure PG, might need casting. 
                # Fallback to simpler check if source_urls[0] == url (Canonical)
                # But let's rely on vector mainly + simple Python logic if needed.
                # Let's skip URL check complexity for a second and rely on Similarity, 
                # because same news from different source will have different URL.
                # Logic: If Vector implies Duplicate -> Skip.
                
                # 2. Vector Dedup
                text_to_embed = f"{item.title} {item.summary}"
                embedding = await generate_embedding(text_to_embed)
                
                is_dup = await self._check_vector_duplicate(embedding)
                if is_dup:
                    logger.info(f"Skipping duplicate (Vector): {item.title}")
                    # TODO: –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å URL –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –Ω–æ–≤–æ—Å—Ç–∏ (Merge), 
                    # –Ω–æ –ø–ª–∞–Ω –≥–æ–≤–æ—Ä–∏—Ç "No Merge Policy" –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã.
                    continue
                
                # 3. Create
                # Parse date safely (Ensure Naive UTC for DB compatibility)
                try:
                    # fromisoformat handles 'Z' in Python 3.11+, but let's be safe
                    dt_str = item.published_at.replace("Z", "+00:00")
                    pub_date = datetime.fromisoformat(dt_str)
                    
                    # Convert to UTC if aware, then strip timezone to make it naive
                    if pub_date.tzinfo is not None:
                        pub_date = pub_date.astimezone(timezone.utc).replace(tzinfo=None)
                        
                except Exception as e:
                    logger.warning(f"Date parse error '{item.published_at}': {e}. Using utcnow.")
                    pub_date = datetime.utcnow()

                news = NewsItem(
                    title=item.title,
                    summary=item.summary,
                    source_urls=[item.source_url], 
                    published_at=pub_date,
                    tags=item.tags,
                    embedding=embedding,
                    status=NewsStatus.PENDING
                )
                self.db.add(news)
                added_count += 1
                
            except Exception as e:
                logger.error(f"Error adding news item '{item.title}': {e}")
                continue
            
        await self.db.commit()
        return added_count

    async def _check_vector_duplicate(self, embedding: List[float]) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –≤ –±–∞–∑–µ –Ω–æ–≤–æ—Å—Ç—å —Å Cosine Similarity > Threshold.
        Distance < (1 - Threshold).
        """
        # Threshold 0.84 sim => 0.16 distance
        distance_threshold = 1.0 - settings.news_dedup_threshold
        
        distance_col = NewsItem.embedding.cosine_distance(embedding)
        
        # –ò—â–µ–º —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –Ω–æ–≤–æ—Å—Ç—å –±–ª–∏–∂–µ —á–µ–º –ø–æ—Ä–æ–≥
        stmt = select(NewsItem.id).where(distance_col < distance_threshold).limit(1)
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none() is not None

    async def find_context_for_query(self, query: str, limit: int = 10) -> str:
        """
        –ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –±–∞–∑–µ –ø–æ –≤–µ–∫—Ç–æ—Ä—É –∑–∞–ø—Ä–æ—Å–∞.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç formatted string –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
        Limit –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10, —á—Ç–æ–±—ã –¥–∞—Ç—å LLM –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–µ–π.
        """
        try:
            # 1. Embed query
            embedding = await generate_embedding(query)
            
            # 2. Search DB (Cosine Distance)
            distance_col = NewsItem.embedding.cosine_distance(embedding)
            
            # Order by distance ASC (closest first)
            stmt = select(NewsItem).order_by(distance_col).limit(limit)
            result = await self.db.execute(stmt)
            items = result.scalars().all()
            
            if not items:
                return "No existing news found."
                
            # 3. Format
            context = ""
            for i, item in enumerate(items, 1):
                context += f"{i}. {item.title} (Published: {item.published_at.date()})\n   Summary: {item.summary}\n"
                
            return context
            
        except Exception as e:
            logger.error(f"Failed to find context for query '{query}': {e}")
            return "Error retrieving context."

    async def search_local_news(self, query: str, limit: int = 10) -> List[NewsItem]:
        """
        –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑–µ –ø–æ –≤–µ–∫—Ç–æ—Ä—É (—Å–º—ã—Å–ª—É).
        """
        try:
            embedding = await generate_embedding(query)
            distance_col = NewsItem.embedding.cosine_distance(embedding)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (distance)
            stmt = select(NewsItem).order_by(distance_col).limit(limit)
            result = await self.db.execute(stmt)
            return result.scalars().all()
        except Exception as e:
            logger.error(f"Local vector search failed for '{query}': {e}")
            return []

    async def trigger_generation(self, news_id: int):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å—Ç–∞—Ç—å–∏ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏.
        """
        news = await self.db.get(NewsItem, news_id)
        if not news:
            return
            
        if news.status == NewsStatus.COMPLETED:
            return
            
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        news.status = NewsStatus.PROCESSING
        await self.db.commit()
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Writer
            item_schema = NewsItemSchema(
                title=news.title,
                summary=news.summary,
                source_url=news.source_urls[0] if news.source_urls else "",
                published_at=news.published_at.isoformat(),
                tags=news.tags or []
            )
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è ‚Äî —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (article, citations, image_url)
            article, citations, image_url = await self.perplexity.generate_article(item_schema)
            
            if article:
                content = article.content
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º citations –≤ source_urls (–¥–æ–ø–æ–ª–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ)
                if citations:
                    existing = news.source_urls or []
                    merged = existing + [u for u in citations if u not in existing]
                    news.source_urls = merged
                    
                    # –ó–∞–º–µ–Ω—è–µ–º [N] –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞ –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–µ markdown-—Å—Å—ã–ª–∫–∏ [[N]](url)
                    def replace_citation(m):
                        idx = int(m.group(1)) - 1  # citations 0-indexed, —Ç–µ–∫—Å—Ç 1-indexed
                        if 0 <= idx < len(citations):
                            return f"[[{m.group(1)}]]({citations[idx]})"
                        return m.group(0)  # –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    content = re.sub(r'\[(\d+)\]', replace_citation, content)
                
                news.content = content
                news.title = article.title  # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ –±–æ–ª–µ–µ –∫—Ä–∞—Å–∏–≤—ã–π –æ—Ç –∞–≤—Ç–æ—Ä–∞
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É (–µ—Å–ª–∏ Perplexity –≤–µ—Ä–Ω—É–ª images[])
                if image_url:
                    news.image_url = image_url
                    logger.info(f"üì∑ Image saved for news {news_id}: {image_url[:80]}")
                
                news.status = NewsStatus.COMPLETED
                return article
                
            else:
                # –ù–µ—É–¥–∞—á–∞ (–ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç)
                raise ValueError("Empty response from Writer")
                
        except Exception as e:
            logger.error(f"Generation failed for news {news_id}: {e}")
            news.status = NewsStatus.FAILED
            news.retry_count += 1
            
        finally:
            news.updated_at = datetime.utcnow()
            await self.db.commit()

    async def get_news_feed(
        self, 
        limit: int = 20, 
        offset: int = 0
    ) -> List[NewsItem]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–µ–Ω—Ç—ã –Ω–æ–≤–æ—Å—Ç–µ–π.
        –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ fresh (published_at).
        """
        stmt = select(NewsItem).order_by(desc(NewsItem.published_at)).offset(offset).limit(limit)
        result = await self.db.execute(stmt)
        return result.scalars().all()

    async def get_personalized_news(
        self,
        user_id: int,
        limit: int = 20
    ) -> List[NewsItem]:
        """
        –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ª–µ–Ω—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π ("–î–ª—è –í–∞—Å").
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ö–≤–∏–∑ + –ü–∞–º—è—Ç—å).
        2. –î–µ–ª–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø—Ä–æ—Ñ–∏–ª—è.
        3. –ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è, –±–ª–∏–∑–∫–∏–µ –ø–æ –≤–µ–∫—Ç–æ—Ä—É.
        4. –ï—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –ø—É—Å—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—ã—á–Ω—É—é –ª–µ–Ω—Ç—É.
        """
        # 1. –°–±–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è
        user_stmt = select(User).where(User.id == user_id)
        user_res = await self.db.execute(user_stmt)
        user = user_res.scalar_one_or_none()
        
        if not user:
            return await self.get_news_feed(limit=limit)
            
        memory_stmt = select(UserMemory).where(UserMemory.user_id == user_id)
        memory_res = await self.db.execute(memory_stmt)
        memory = memory_res.scalar_one_or_none()
        
        profile_text = ""
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç—ã –Ω–∞ –∫–≤–∏–∑ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if user.quiz_answers:
            # quiz_answers is list of strings
            profile_text += "Interests: " + ", ".join(map(str, user.quiz_answers)) + ". "
            
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—Ä—Ä–∞—Ç–∏–≤–Ω—É—é –ø–∞–º—è—Ç—å
        if memory and memory.narrative_summary:
            profile_text += f"Context: {memory.narrative_summary}"
            
        if not profile_text.strip():
            # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ -> –æ–±—ã—á–Ω–∞—è –ª–µ–Ω—Ç–∞
            return await self.get_news_feed(limit=limit)
            
        try:
            # 2. –≠–º–±–µ–¥–¥–∏–Ω–≥ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤
            user_embedding = await generate_embedding(profile_text)
            
            # 3. –ü–æ–∏—Å–∫ (Hybrid: Time + Vector)
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ (3 –¥–Ω—è)
            since_date = datetime.utcnow() - timedelta(days=3)
            
            distance_col = NewsItem.embedding.cosine_distance(user_embedding)
            
            stmt = (
                select(NewsItem)
                .where(NewsItem.published_at >= since_date)
                .order_by(distance_col) # –°–∞–º—ã–µ –±–ª–∏–∑–∫–∏–µ –ø–æ —Å–º—ã—Å–ª—É
                .limit(limit)
            )
            
            result = await self.db.execute(stmt)
            items = result.scalars().all()
            
            # –ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –º–∞–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–µ–ª –∏–ª–∏ –±–∞–∑–∞ –ø—É—Å—Ç–∞—è),
            # –¥–æ–ª–∏–≤–∞–µ–º –æ–±—ã—á–Ω—ã–º–∏ —Å–≤–µ–∂–∏–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏
            if len(items) < limit:
                needed = limit - len(items)
                existing_ids = [n.id for n in items]
                
                fallback_stmt = (
                    select(NewsItem)
                    .where(NewsItem.published_at >= since_date)
                    .where(NewsItem.id.notin_(existing_ids))
                    .order_by(desc(NewsItem.published_at))
                    .limit(needed)
                )
                fallback_res = await self.db.execute(fallback_stmt)
                items.extend(fallback_res.scalars().all())
                
            return items
            
        except Exception as e:
            logger.error(f"Personalization failed for user {user_id}: {e}")
            # Fallback to standard feed
            return await self.get_news_feed(limit=limit)
