"""
backfill_news_images.py

–ü—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –≤—Å–µ–º –Ω–æ–≤–æ—Å—Ç—è–º –±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –ø—ã—Ç–∞–µ—Ç—Å—è –¥–æ—Å—Ç–∞—Ç—å og:image
–∏–∑ source_urls. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é.

–ó–∞–ø—É—Å–∫ (–≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –∏–ª–∏ —Å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–º venv):
    python scripts/backfill_news_images.py

–ò–ª–∏ —á–µ—Ä–µ–∑ docker:
    docker exec uii-backend python scripts/backfill_news_images.py
"""

import sys
import os
import asyncio
import re

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import httpx
from loguru import logger
from sqlalchemy import select
from database import async_session_factory
from models import NewsItem

# ---- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ----
REQUEST_TIMEOUT = 6.0      # —Å–µ–∫—É–Ω–¥ –Ω–∞ –æ–¥–∏–Ω HTTP-–∑–∞–ø—Ä–æ—Å
DELAY_BETWEEN = 0.3        # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—á—Ç–æ–±—ã –Ω–µ —Ñ–ª—É–¥–∏—Ç—å)
USER_AGENT = "Mozilla/5.0 (compatible; UII-Backfiller/1.0)"

OG_IMAGE_RE = re.compile(
    r'<meta[^>]+property=["\']og:image["\'][^>]+content=["\'](https?://[^"\'>\s]+)["\']',
    re.IGNORECASE,
)
# –í—Ç–æ—Ä–æ–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî content –ø–µ—Ä–µ–¥ property
OG_IMAGE_RE2 = re.compile(
    r'<meta[^>]+content=["\'](https?://[^"\'>\s]+)["\'][^>]+property=["\']og:image["\']',
    re.IGNORECASE,
)


async def fetch_og_image(url: str, client: httpx.AsyncClient) -> str | None:
    """–î–µ–ª–∞–µ—Ç GET –Ω–∞ url –∏ –∏—â–µ—Ç og:image. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–ª–∏ None."""
    try:
        r = await client.get(url, timeout=REQUEST_TIMEOUT, follow_redirects=True)
        if r.status_code != 200:
            return None
        html = r.text
        m = OG_IMAGE_RE.search(html) or OG_IMAGE_RE2.search(html)
        if m:
            return m.group(1).strip()
    except Exception as e:
        logger.warning(f"  ‚ö†Ô∏è  GET {url[:80]} failed: {e}")
    return None


async def backfill():
    logger.info("üöÄ Starting news image backfill...")

    async with async_session_factory() as db:
        # –¢–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–∏ –±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏
        result = await db.execute(
            select(NewsItem)
            .where(NewsItem.image_url.is_(None))
            .order_by(NewsItem.id)
        )
        news_list = result.scalars().all()

    total = len(news_list)
    logger.info(f"üì∞ Found {total} news items without image_url")

    if total == 0:
        logger.info("‚úÖ Nothing to do.")
        return

    found = 0
    skipped = 0

    async with httpx.AsyncClient(headers={"User-Agent": USER_AGENT}) as client:
        for i, news in enumerate(news_list, 1):
            urls = news.source_urls or []
            if not urls:
                logger.info(f"[{i}/{total}] ID={news.id} ‚Äî no source_urls, skip")
                skipped += 1
                continue

            logger.info(f"[{i}/{total}] ID={news.id} ‚Äî trying {len(urls)} URL(s)...")
            image_url = None

            for url in urls:
                image_url = await fetch_og_image(url, client)
                if image_url:
                    logger.info(f"  ‚úÖ Found: {image_url[:100]}")
                    break
                await asyncio.sleep(DELAY_BETWEEN)

            if image_url:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å–µ—Å—Å–∏–∏ –Ω–∞ –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å
                async with async_session_factory() as db:
                    item = await db.get(NewsItem, news.id)
                    if item:
                        item.image_url = image_url
                        await db.commit()
                found += 1
            else:
                logger.info(f"  ‚ùå No og:image found for ID={news.id}")
                skipped += 1

            await asyncio.sleep(DELAY_BETWEEN)

    logger.info(
        f"\nüèÅ Done. Updated: {found}/{total}, skipped/not found: {skipped}/{total}"
    )


if __name__ == "__main__":
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(backfill())
