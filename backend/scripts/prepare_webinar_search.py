"""
–°–∫—Ä–∏–ø—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ AI-–ø–æ–∏—Å–∫–∞ –ø–æ –≤–µ–±–∏–Ω–∞—Ä–∞–º.

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–µ–±–∏–Ω–∞—Ä–∞ –≤ WebinarLibrary –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç:
  1. short_description  ‚Äî –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) —á–µ—Ä–µ–∑ gpt-4.1-mini
                          –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û –≤ LLM re-ranking (–Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º)
  2. search_embedding   ‚Äî –≤–µ–∫—Ç–æ—Ä (title + description) —á–µ—Ä–µ–∑ text-embedding-3-small
                          –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è cosine search

–ó–∞–ø—É—Å–∫:
    cd backend
    python scripts/prepare_webinar_search.py

–§–ª–∞–≥–∏:
    --force   ‚Äî –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ –ø–æ–ª—è —É–∂–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã
    --dry-run ‚Äî —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (–±–µ–∑ –∑–∞–ø–∏—Å–∏ –≤ –ë–î)
"""
import asyncio
import os
import sys
import argparse

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import sessionmaker
from loguru import logger
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()

from database import async_engine
from models import WebinarLibrary
from services.openai_service import generate_embedding

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger.add("prepare_webinar_search.log", rotation="10 MB", level="INFO")

SUMMARY_MODEL = "gpt-4.1-mini"
SUMMARY_PROMPT = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞—ë—Ç –∫—Ä–∞—Ç–∫–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –≤–µ–±–∏–Ω–∞—Ä–æ–≤.

–ù–∞ –≤—Ö–æ–¥ —Ç—ã –ø–æ–ª—É—á–∞–µ—à—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–µ–±–∏–Ω–∞—Ä–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –Ω–∞–ø–∏—Å–∞—Ç—å 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è,
–∫—Ä–∞—Ç–∫–æ –ø–µ—Ä–µ–¥–∞—é—â–∏—Ö —Å—É—Ç—å —Ç–µ–º—ã. –ù–µ –ø–∏—à–∏ —Å–ª–æ–≤–∞ "–≤–µ–±–∏–Ω–∞—Ä", "—Å–ø–∏–∫–µ—Ä", "–∑–∞–ø–∏—Å—å". –¢–æ–ª—å–∫–æ —Å—É—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

–ù–∞–∑–≤–∞–Ω–∏–µ: {title}
–û–ø–∏—Å–∞–Ω–∏–µ: {description}

–ù–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é, –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤."""


async def get_db_session() -> AsyncSession:
    async_session = sessionmaker(
        async_engine, class_=AsyncSession, expire_on_commit=False
    )
    return async_session()


async def generate_short_description(client: AsyncOpenAI, title: str, description: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–µ–±–∏–Ω–∞—Ä–∞ —á–µ—Ä–µ–∑ LLM (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."""
    prompt = SUMMARY_PROMPT.format(
        title=title,
        description=description or "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ"
    )
    
    response = await client.chat.completions.create(
        model=SUMMARY_MODEL,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=200,
        temperature=0.3
    )
    
    return response.choices[0].message.content.strip()


async def prepare_search(force: bool = False, dry_run: bool = False):
    logger.info(f"üöÄ Starting webinar search preparation (force={force}, dry_run={dry_run})")
    
    client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    async with await get_db_session() as db:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –≤–µ–±–∏–Ω–∞—Ä—ã
        result = await db.execute(select(WebinarLibrary).order_by(WebinarLibrary.id))
        webinars = result.scalars().all()
        
        logger.info(f"Found {len(webinars)} webinars in library")
        
        processed = 0
        skipped = 0
        errors = 0
        
        for webinar in webinars:
            needs_summary = force or not webinar.short_description
            needs_embedding = force or webinar.search_embedding is None
            
            if not needs_summary and not needs_embedding:
                logger.info(f"  ‚è≠Ô∏è  [{webinar.id}] '{webinar.title}' ‚Äî already prepared, skipping")
                skipped += 1
                continue
            
            logger.info(f"  üîÑ [{webinar.id}] Processing: '{webinar.title}'")
            
            if dry_run:
                logger.info(f"     [DRY-RUN] Would generate: summary={needs_summary}, embedding={needs_embedding}")
                continue
            
            try:
                # 1. –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ LLM
                if needs_summary:
                    short_desc = await generate_short_description(
                        client,
                        title=webinar.title,
                        description=webinar.description or ""
                    )
                    webinar.short_description = short_desc
                    logger.info(f"     ‚úÖ short_description: {short_desc[:80]}...")
                
                # 2. Embedding –ø–æ title + description
                if needs_embedding:
                    text_to_embed = f"{webinar.title}\n\n{webinar.description or ''}"
                    embedding = await generate_embedding(text_to_embed)
                    webinar.search_embedding = embedding
                    logger.info(f"     ‚úÖ embedding generated ({len(embedding)} dims)")
                
                db.add(webinar)
                await db.commit()
                processed += 1
                logger.info(f"     üíæ Saved [{webinar.id}]")
                
            except Exception as e:
                logger.error(f"     ‚ùå Error processing [{webinar.id}] '{webinar.title}': {e}")
                await db.rollback()
                errors += 1
    
    logger.info(
        f"\nüéâ Done! Processed: {processed}, Skipped: {skipped}, Errors: {errors}"
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Prepare webinar AI search data")
    parser.add_argument("--force", action="store_true", help="Regenerate even if already filled")
    parser.add_argument("--dry-run", action="store_true", help="Only show what would be done")
    args = parser.parse_args()
    
    asyncio.run(prepare_search(force=args.force, dry_run=args.dry_run))
